{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo3 Finetuning with AWS\n",
    "\n",
    "This series of notebooks demonstrates how to finetune pretrained YOLO v3 (aka YOLO3) using MXNet on AWS.\n",
    "\n",
    "**This notebook** walks through using the [SageMaker Hyperparameter Tuning Job](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) tool to finding optmized hypterparameter and finetune the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Follow-on** the content of the notebooks shows:\n",
    "\n",
    "* How to use MXNet YOLO3 pretrained model\n",
    "* How to create Ground-Truth dataset from images the model mis-detected\n",
    "* How to finetune the model using the created dataset\n",
    "* Load your finetuned model and Deploy Sagemaker-Endpoint with it.\n",
    "* Apply Elastic Inference to your endpoint.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "This notebook is designed to be run in Amazon SageMaker. To run it (and understand what's going on), you'll need:\n",
    "\n",
    "* Basic familiarity with Python, [MXNet](https://mxnet.apache.org/), [AWS S3](https://docs.aws.amazon.com/s3/index.html), [Amazon Sagemaker](https://aws.amazon.com/sagemaker/)\n",
    "* To create an **S3 bucket** in the same region, and ensure the SageMaker notebook's role has access to this bucket.\n",
    "* Sufficient [SageMaker quota limits](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_sagemaker) set on your account to run GPU-accelerated spot training jobs.\n",
    "\n",
    "## Cost and runtime\n",
    "\n",
    "Depending on your configuration, this demo may consume resources outside of the free tier but should not generally be expensive because we'll be training on a small number of images. You might wish to review the following for your region:\n",
    "\n",
    "* [Amazon SageMaker pricing](https://aws.amazon.com/sagemaker/pricing/)\n",
    "\n",
    "The standard `ml.t2.medium` instance should be sufficient to run the notebooks.\n",
    "\n",
    "We will use GPU-accelerated instance types for training and hyperparameter optimization, and use spot instances where appropriate to optimize these costs.\n",
    "\n",
    "As noted in the step-by-step guidance, you should take particular care to delete any created SageMaker real-time prediction endpoints when finishing the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Dependencies and configuration\n",
    "\n",
    "As usual we'll start by loading libraries, defining configuration, and connecting to the AWS SDKs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
