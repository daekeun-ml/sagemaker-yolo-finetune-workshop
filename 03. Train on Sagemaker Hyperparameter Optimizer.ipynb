{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo3 Finetuning with AWS\n",
    "\n",
    "This series of notebooks demonstrates how to finetune pretrained YOLO v3 (aka YOLO3) using MXNet on AWS.\n",
    "\n",
    "**This notebook** walks through using the [SageMaker Hyperparameter Tuning Job](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) tool to finding optmized hypterparameter and finetune the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Follow-on** the content of the notebooks shows:\n",
    "\n",
    "* How to use MXNet YOLO3 pretrained model\n",
    "* How to create Ground-Truth dataset from images the model mis-detected\n",
    "* How to finetune the model using the created dataset\n",
    "* Load your finetuned model and Deploy Sagemaker-Endpoint with it.\n",
    "* Apply Elastic Inference to your endpoint.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "This notebook is designed to be run in Amazon SageMaker. To run it (and understand what's going on), you'll need:\n",
    "\n",
    "* Basic familiarity with Python, [MXNet](https://mxnet.apache.org/), [AWS S3](https://docs.aws.amazon.com/s3/index.html), [Amazon Sagemaker](https://aws.amazon.com/sagemaker/)\n",
    "* To create an **S3 bucket** in the same region, and ensure the SageMaker notebook's role has access to this bucket.\n",
    "* Sufficient [SageMaker quota limits](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_sagemaker) set on your account to run GPU-accelerated spot training jobs.\n",
    "\n",
    "## Cost and runtime\n",
    "\n",
    "Depending on your configuration, this demo may consume resources outside of the free tier but should not generally be expensive because we'll be training on a small number of images. You might wish to review the following for your region:\n",
    "\n",
    "* [Amazon SageMaker pricing](https://aws.amazon.com/sagemaker/pricing/)\n",
    "\n",
    "The standard `ml.t2.medium` instance should be sufficient to run the notebooks.\n",
    "\n",
    "We will use GPU-accelerated instance types for training and hyperparameter optimization, and use spot instances where appropriate to optimize these costs.\n",
    "\n",
    "As noted in the step-by-step guidance, you should take particular care to delete any created SageMaker real-time prediction endpoints when finishing the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Dependencies and configuration\n",
    "\n",
    "As usual we'll start by loading libraries, defining configuration, and connecting to the AWS SDKs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongkyl/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Built-Ins:\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import imageio\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.mxnet import MXNet\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore stored variables\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "s3 = session.resource('s3')\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "smclient = session.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client('iam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-ap-northeast-2-929831892372\n"
     ]
    }
   ],
   "source": [
    "print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Recap output.manifest\n",
    "\n",
    "In last notebook, we made the *output.manifest* that is containing annotation infromation along with image location. And here is the content of the file.\n",
    "\n",
    "content is dictionary having 2 essential keys, *labels* and *source-ref*. \n",
    "- **labels** - contains information of bounding boxes in the value under key *annotations*.  *class_id* is always *0* because we have only one class *person* in the dataset.\n",
    "- **source-ref** - same value as in *input.manifest* file\n",
    "\n",
    "For introduction to model training and deployment, see [**Train a Model with Amazon SageMaker**](http://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_manifest_path = f'annotations/{job_name}/manifests/output/output.manifest'\n",
    "output_manifest_obj = bucket.Object(output_manifest_path)\n",
    "dataset = output_manifest_obj.get()['Body'].read().decode('utf-8').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"source-ref\":\"s3://sagemaker-ap-northeast-2-929831892372/yolo-workshop-batch/images/235.jpg\",\"labels\":{\"annotations\":[{\"class_id\":0,\"width\":182,\"top\":45,\"height\":230,\"left\":90},{\"class_id\":0,\"width\":174,\"top\":0,\"height\":231,\"left\":150}],\"image_size\":[{\"width\":427,\"depth\":3,\"height\":320}]},\"labels-metadata\":{\"job-name\":\"labeling-job/yolo-job-0\",\"class-map\":{\"0\":\"Person\"},\"human-annotated\":\"yes\",\"objects\":[{\"confidence\":0.09},{\"confidence\":0.09}],\"creation-date\":\"2020-03-14T12:51:04.692288\",\"type\":\"groundtruth/object-detection\"}}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': {'annotations': [{'class_id': 0,\n",
      "                             'height': 230,\n",
      "                             'left': 90,\n",
      "                             'top': 45,\n",
      "                             'width': 182},\n",
      "                            {'class_id': 0,\n",
      "                             'height': 231,\n",
      "                             'left': 150,\n",
      "                             'top': 0,\n",
      "                             'width': 174}],\n",
      "            'image_size': [{'depth': 3, 'height': 320, 'width': 427}]},\n",
      " 'labels-metadata': {'class-map': {'0': 'Person'},\n",
      "                     'creation-date': '2020-03-14T12:51:04.692288',\n",
      "                     'human-annotated': 'yes',\n",
      "                     'job-name': 'labeling-job/yolo-job-0',\n",
      "                     'objects': [{'confidence': 0.09}, {'confidence': 0.09}],\n",
      "                     'type': 'groundtruth/object-detection'},\n",
      " 'source-ref': 's3://sagemaker-ap-northeast-2-929831892372/yolo-workshop-batch/images/235.jpg'}\n"
     ]
    }
   ],
   "source": [
    "pprint(json.loads(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split dataset into Train and Test datasets\n",
    "\n",
    "Split dataset into train and test datasets is common procedure in Machine Learning(ML).\n",
    "\n",
    "There are several methods to do that, and we are going to use the simplest one in here. We are going to shuffle entire dataset and split with ratio of 9:1 for train and test respectively.\n",
    "\n",
    "After split, you will get 2 files, *train.manifest* and *test.manifest* in the path that *output.manifest* is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'n_samples_train' (int)\n",
      "Stored 'n_samples_test' (int)\n",
      "Training manifest uploaded to:\n",
      "s3://sagemaker-ap-northeast-2-929831892372/annotations/yolo-job-0/manifests/output/train.manifest\n",
      "Test manifest uploaded to:\n",
      "s3://sagemaker-ap-northeast-2-929831892372/annotations/yolo-job-0/manifests/output/test.manifest\n"
     ]
    }
   ],
   "source": [
    "RATIO = 0.9\n",
    "\n",
    "# shuffle dataset\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "n_samples_total = len(dataset)\n",
    "train_test_split_index = round(n_samples_total*0.9)\n",
    "\n",
    "# split datasets\n",
    "train_dataset = dataset[:train_test_split_index]\n",
    "test_dataset = dataset[train_test_split_index:]\n",
    "\n",
    "n_samples_train = len(train_dataset)\n",
    "%store n_samples_train\n",
    "n_samples_test = len(test_dataset)\n",
    "%store n_samples_test\n",
    "\n",
    "# store manifests into localhost\n",
    "with open(f'train.manifest', 'w') as f:\n",
    "    for line in train_dataset:\n",
    "        if not line:\n",
    "            continue\n",
    "        f.write(str(line))\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "with open(f'test.manifest', 'w') as f:\n",
    "    for line in test_dataset:\n",
    "        if not line:\n",
    "            continue\n",
    "        f.write(str(line))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "# store train/test manifests to s3 bucket where output.manifest is located.\n",
    "manifest_path = output_manifest_path.rsplit('/', 1)[0]\n",
    "bucket.upload_file('train.manifest', f'{manifest_path}/train.manifest')\n",
    "print('Training manifest uploaded to:\\n' + f's3://{bucket.name}/{manifest_path}/train.manifest')\n",
    "bucket.upload_file('test.manifest', f'{manifest_path}/test.manifest')\n",
    "print('Test manifest uploaded to:\\n' + f\"s3://{bucket.name}/{manifest_path}/test.manifest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Hyperparameter Tuning Job\n",
    "\n",
    "Now, you are ready to finetune MXNet YOLO model with *train.manifest* and *test.manifest* datasets.\n",
    "\n",
    "Of course, you create hyperparameter tuning job on AWS Console but there is much easier way to do the same job on sagemaker notebook.\n",
    "\n",
    "Sagemaker provide *sagemaker.mxnet.MXNet* estimator to train model. With this class you can train or make hyperparameter tuning job for your own model.\n",
    "\n",
    "First of all, you should define metric for estimator. The estimator's goal is mininize or maximize the metric you gave to it.\n",
    "\n",
    "In this chapter we are going to use *Loss* as a metric which means the goal of the estimator is going to be minize it as much as it can. \n",
    "\n",
    "The estimator container will automatically capture it's *stdout* and find the *Regex* pattern you difined and make it as metric to minize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    { 'Name': 'TrainLoss', 'Regex': 'Train Loss: (.*?) ;' },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have execution role for sagemaker just put it to the *role_name* on below cell.\n",
    "\n",
    "Let's make IAM role on [**AWS Console**]() with *AmazonSagemakerFullAccess* Policy like below screen. \n",
    "\n",
    "<img src=\"Assets/ExecutionRole.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'role_name' (str)\n"
     ]
    }
   ],
   "source": [
    "# replace role_name with yours\n",
    "role_name = 'AmazonSageMaker-ExecutionRole-20200129T183159'\n",
    "%store role_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = iam.get_role(RoleName=role_name)['Role']['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make estiamtor. Estimator handles end-to-end Amazon SageMaker training and deployment tasks.\n",
    "\n",
    "You can run your training job on *Spot Instance* and we are going to do that, because using spot instance is the most cost efficient way to run your job on AWS.\n",
    "\n",
    "The estimator we are making, uses *4 of ml.p3.8xlarge Spot instances* for training so that 4 Hyperparameter tuning job is able to run cucurrently.\n",
    "\n",
    "Let me explain some important parameters before run the code,\n",
    "\n",
    "* entry_point - python script that includes train/finetune logics.\n",
    "* source_dir - local folder location that `entry_point` is placed.\n",
    "* frame_work_version - MXNet framework version\n",
    "* input_mode - 'File' or 'Pipe'. entry_point should be implemented considering input_mode.\n",
    "* train_use_spot_instances - True if you want to use spot-instance for running training jobs.\n",
    "* output_path - s3 bucket path that models and checkpoints will be stored.\n",
    "* hyperparameters - default hyperparameters. most of the values will be overriden by hyperparameter tuning job. (look into *hyperparameter_ranges* variable below cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNet(\n",
    "    role=role,\n",
    "    entry_point='yolo_finetune.py',\n",
    "    source_dir='src',\n",
    "    framework_version='1.4.1',\n",
    "    py_version='py3',\n",
    "    input_mode='File',\n",
    "    train_volume_size=n_samples_train,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p3.8xlarge',\n",
    "    train_max_run=5*60*60,\n",
    "    train_use_spot_instances=True,\n",
    "    train_max_wait=5*60*60,\n",
    "    metric_definitions=metric_definitions,\n",
    "    base_job_name='yolo-finetune-0',\n",
    "    output_path=f\"s3://{BUCKET_NAME}/{MODELS_PREFIX}\",\n",
    "    hyperparameters={\n",
    "        'epochs': 30,\n",
    "        'num-workers': 4,\n",
    "        'batch-size': 8,\n",
    "        'num-gpus': 4,\n",
    "        'data-shape': 320,\n",
    "        'lr': 0.000361,\n",
    "        'momentum': 0.299848,\n",
    "        'wd': 0.986724,\n",
    "        'optimizer': 'sgd',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Prepare channel\n",
    "\n",
    "HyperParameter tuning job requires data channel for fetch data from s3.\n",
    "\n",
    "Estimator on *File* mode, *image_channel* must be provided to the tuner because Sagemaker training container copies all train/test images on creating container instance using *image_channel*.\n",
    "\n",
    "We are using *File* mode because our dataset is small enough but if you are planning to deal with very large dataset consider *Pipe* mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass only essential keys\n",
    "attribute_names = ['source-ref', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = sagemaker.session.s3_input(\n",
    "    f's3://{BUCKET_NAME}/{manifest_path}/train.manifest',\n",
    "    distribution='FullyReplicated',\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    attribute_names=attribute_names\n",
    ")\n",
    "                                        \n",
    "test_channel = sagemaker.session.s3_input(\n",
    "    f's3://{BUCKET_NAME}/{manifest_path}/test.manifest',\n",
    "    distribution='FullyReplicated',\n",
    "    s3_data_type='S3Prefix',\n",
    "    attribute_names=attribute_names\n",
    ")\n",
    "\n",
    "image_channel = sagemaker.session.s3_input(\n",
    "    f's3://{BUCKET_NAME}/{BATCH_NAME}/{IMAGE_PREFIX}',\n",
    "    s3_data_type=\"S3Prefix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Finetune Model using Hyperparameter tuning job\n",
    "\n",
    "[How Hyperparameter Tuning Works](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) says dailed information about hyperparmeter tuning job.\n",
    "\n",
    "Simply put it, hyperparameter tuning job test all of the *likely* parameters in the given range, and find best combination of the parameters for the model with given dataset.\n",
    "\n",
    "In this manner, you should provide ranges of the hyperparameters where the best parameters lie on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'lr': sagemaker.tuner.ContinuousParameter(0.0001, 0.1),\n",
    "    'momentum': sagemaker.tuner.ContinuousParameter(0.0, 0.99),\n",
    "    'wd': sagemaker.tuner.ContinuousParameter(0.0, 0.99),\n",
    "    'optimizer': sagemaker.tuner.CategoricalParameter(['sgd', 'adam', 'rmsprop', 'adadelta'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the all together, such as estimator, metric(or loss), hyperparameter ranges, we are going to run Hyperparameter Tuning Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator,\n",
    "    'TrainLoss',\n",
    "    objective_type='Minimize',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    base_tuning_job_name='yolo-htj-batch-0',\n",
    "    max_jobs=24,\n",
    "    max_parallel_jobs=3\n",
    ")\n",
    "\n",
    "tuner.fit(\n",
    "    {\n",
    "        \"train\": train_channel,\n",
    "        \"test\": test_channel,\n",
    "        \"images\": image_channel\n",
    "    },\n",
    "    include_cls_metadata=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you call *fit()* method, you can check the progress on [AWS Console](https://console.aws.amazon.com).\n",
    "\n",
    "<img src=\"Assets/TrainingJobStatus.png\" />\n",
    "\n",
    "and, of course, you can check progress out on the notebook using Sagemaker Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_jobs = smclient.list_training_jobs(NameContains=tuner.base_tuning_job_name, StatusEquals='InProgress')\n",
    "training_job_name = training_jobs['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "training_job_name = training_job_name.rsplit('-', 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>wd</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>\"rmsprop\"</td>\n",
       "      <td>0.919253</td>\n",
       "      <td>yolo-htj-batch-0-200316-1644-009-35aacd8f</td>\n",
       "      <td>InProgress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-16 17:03:48+09:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.977348</td>\n",
       "      <td>\"rmsprop\"</td>\n",
       "      <td>0.760640</td>\n",
       "      <td>yolo-htj-batch-0-200316-1644-008-e611c6f2</td>\n",
       "      <td>InProgress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-16 17:03:27+09:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.981971</td>\n",
       "      <td>\"rmsprop\"</td>\n",
       "      <td>0.955925</td>\n",
       "      <td>yolo-htj-batch-0-200316-1644-007-50aed652</td>\n",
       "      <td>InProgress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-16 17:03:12+09:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.827797</td>\n",
       "      <td>\"rmsprop\"</td>\n",
       "      <td>0.984417</td>\n",
       "      <td>yolo-htj-batch-0-200316-1644-006-eb95c198</td>\n",
       "      <td>Completed</td>\n",
       "      <td>17.080259</td>\n",
       "      <td>2020-03-16 16:55:15+09:00</td>\n",
       "      <td>2020-03-16 16:59:52+09:00</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.886767</td>\n",
       "      <td>\"adadelta\"</td>\n",
       "      <td>0.874761</td>\n",
       "      <td>yolo-htj-batch-0-200316-1644-005-187ae30f</td>\n",
       "      <td>Completed</td>\n",
       "      <td>18.642727</td>\n",
       "      <td>2020-03-16 16:54:46+09:00</td>\n",
       "      <td>2020-03-16 17:01:08+09:00</td>\n",
       "      <td>382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017444</td>\n",
       "      <td>0.607785</td>\n",
       "      <td>\"rmsprop\"</td>\n",
       "      <td>0.918029</td>\n",
       "      <td>yolo-htj-batch-0-200316-1644-004-4211ee3a</td>\n",
       "      <td>Completed</td>\n",
       "      <td>17.322720</td>\n",
       "      <td>2020-03-16 16:55:06+09:00</td>\n",
       "      <td>2020-03-16 16:59:38+09:00</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.872681</td>\n",
       "      <td>\"rmsprop\"</td>\n",
       "      <td>0.980190</td>\n",
       "      <td>yolo-htj-batch-0-200316-1644-003-302f6f04</td>\n",
       "      <td>Completed</td>\n",
       "      <td>16.591208</td>\n",
       "      <td>2020-03-16 16:47:43+09:00</td>\n",
       "      <td>2020-03-16 16:52:13+09:00</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.981114</td>\n",
       "      <td>\"sgd\"</td>\n",
       "      <td>0.988343</td>\n",
       "      <td>yolo-htj-batch-0-200316-1644-002-63f17640</td>\n",
       "      <td>Completed</td>\n",
       "      <td>23.466627</td>\n",
       "      <td>2020-03-16 16:47:36+09:00</td>\n",
       "      <td>2020-03-16 16:51:42+09:00</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.878604</td>\n",
       "      <td>\"rmsprop\"</td>\n",
       "      <td>0.844688</td>\n",
       "      <td>yolo-htj-batch-0-200316-1644-001-6e24a710</td>\n",
       "      <td>Completed</td>\n",
       "      <td>16.396324</td>\n",
       "      <td>2020-03-16 16:47:50+09:00</td>\n",
       "      <td>2020-03-16 16:52:13+09:00</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr  momentum   optimizer        wd  \\\n",
       "0  0.000104  0.960192   \"rmsprop\"  0.919253   \n",
       "1  0.089686  0.977348   \"rmsprop\"  0.760640   \n",
       "2  0.000100  0.981971   \"rmsprop\"  0.955925   \n",
       "3  0.011254  0.827797   \"rmsprop\"  0.984417   \n",
       "4  0.000575  0.886767  \"adadelta\"  0.874761   \n",
       "5  0.017444  0.607785   \"rmsprop\"  0.918029   \n",
       "6  0.000489  0.872681   \"rmsprop\"  0.980190   \n",
       "7  0.010015  0.981114       \"sgd\"  0.988343   \n",
       "8  0.001161  0.878604   \"rmsprop\"  0.844688   \n",
       "\n",
       "                             TrainingJobName TrainingJobStatus  \\\n",
       "0  yolo-htj-batch-0-200316-1644-009-35aacd8f        InProgress   \n",
       "1  yolo-htj-batch-0-200316-1644-008-e611c6f2        InProgress   \n",
       "2  yolo-htj-batch-0-200316-1644-007-50aed652        InProgress   \n",
       "3  yolo-htj-batch-0-200316-1644-006-eb95c198         Completed   \n",
       "4  yolo-htj-batch-0-200316-1644-005-187ae30f         Completed   \n",
       "5  yolo-htj-batch-0-200316-1644-004-4211ee3a         Completed   \n",
       "6  yolo-htj-batch-0-200316-1644-003-302f6f04         Completed   \n",
       "7  yolo-htj-batch-0-200316-1644-002-63f17640         Completed   \n",
       "8  yolo-htj-batch-0-200316-1644-001-6e24a710         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0                  NaN 2020-03-16 17:03:48+09:00                       NaT   \n",
       "1                  NaN 2020-03-16 17:03:27+09:00                       NaT   \n",
       "2                  NaN 2020-03-16 17:03:12+09:00                       NaT   \n",
       "3            17.080259 2020-03-16 16:55:15+09:00 2020-03-16 16:59:52+09:00   \n",
       "4            18.642727 2020-03-16 16:54:46+09:00 2020-03-16 17:01:08+09:00   \n",
       "5            17.322720 2020-03-16 16:55:06+09:00 2020-03-16 16:59:38+09:00   \n",
       "6            16.591208 2020-03-16 16:47:43+09:00 2020-03-16 16:52:13+09:00   \n",
       "7            23.466627 2020-03-16 16:47:36+09:00 2020-03-16 16:51:42+09:00   \n",
       "8            16.396324 2020-03-16 16:47:50+09:00 2020-03-16 16:52:13+09:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                       277.0  \n",
       "4                       382.0  \n",
       "5                       272.0  \n",
       "6                       270.0  \n",
       "7                       246.0  \n",
       "8                       263.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytics = sagemaker.HyperparameterTuningJobAnalytics(training_job_name)\n",
    "analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Check out best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Best training job not available for tuning job: yolo-htj-batch-0-200316-0114",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36m_get_best_training_job\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtuning_job_describe_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BestTrainingJob\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BestTrainingJob'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-74ed0ebeea5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36mbest_estimator\u001b[0;34m(self, best_training_job)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \"\"\"\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbest_training_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mbest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_best_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sagemaker/tuner.py\u001b[0m in \u001b[0;36m_get_best_training_job\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m             raise Exception(\n\u001b[1;32m    808\u001b[0m                 \"Best training job not available for tuning job: {}\".format(\n\u001b[0;32m--> 809\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_tuning_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m                 )\n\u001b[1;32m    811\u001b[0m             )\n",
      "\u001b[0;31mException\u001b[0m: Best training job not available for tuning job: yolo-htj-batch-0-200316-0114"
     ]
    }
   ],
   "source": [
    "est = tuner.best_estimator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
